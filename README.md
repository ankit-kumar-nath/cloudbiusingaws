Cloud-Based Business Intelligence & Sales Forecasting Platform (AWS + Streamlit)

A fully automated cloud-native BI, Forecasting, and Inventory Optimization System.

ğŸ“Œ Overview

This project implements an end-to-end Business Intelligence system powered by AWS.
Users can upload sales data (CSV/PDF), which is automatically processed through a serverless cloud pipeline to generate:

KPI dashboards

Sales trends & visual analytics

Demand forecasting (ARIMA / Prophet / SageMaker)

Inventory optimization (EOQ, Reorder Point, Dead Stock)

The final insights are displayed on an interactive Streamlit dashboard.

ğŸ—ï¸ System Architecture
User Upload â†’ S3 (Raw Zone)
            â†’ Lambda (Validation)
            â†’ Glue (ETL)
            â†’ S3 (Curated Zone)
            â†’ Athena (Query Engine)
            â†’ Forecast Models (ARIMA / Prophet / SageMaker)
            â†’ S3 (Predictions)
            â†’ Streamlit Dashboard

S3 Data Lake Structure
raw/
curated/
training/
predictions/
logs/
scripts/
athena-results/

âœ¨ Key Features
ğŸ”¹ 1. Automated Ingestion

Upload CSV or PDF

Auto-schema detection

S3 storage with serverless triggers

ğŸ”¹ 2. ETL Processing (AWS Glue)

Cleans and validates data

Removes duplicates & fixes formats

Converts to Parquet for faster queries

ğŸ”¹ 3. BI Analytics

Revenue, profit, product performance

Regional sales analysis

Customer segmentation (RFM)

Time-series visualizations

ğŸ”¹ 4. Demand Forecasting

Supports:

Prophet

ARIMA

SageMaker models

Outputs include:

Forecast values

Confidence intervals

Seasonal components

ğŸ”¹ 5. Inventory Optimization

EOQ (Economic Order Quantity)

Reorder Point calculation

Safety stock estimation

Dead stock identification

ğŸ”¹ 6. Interactive Dashboard (Streamlit)

KPI cards

Forecast charts

Downloadable reports

Clean and user-friendly UI

ğŸ› ï¸ Tech Stack
Frontend / Dashboard

Streamlit

Plotly

Pandas, NumPy

Cloud Services (AWS)

S3

Lambda

Glue

Athena

SageMaker

CloudWatch

IAM

Machine Learning

Prophet

Statsmodels (ARIMA)

Amazon SageMaker

ğŸ“‚ Project Structure
â”œâ”€â”€ ingestion/
â”‚   â”œâ”€â”€ csv_loader.py
â”‚   â”œâ”€â”€ pdf_loader.py
â”‚   â”œâ”€â”€ schema_detector.py
â”‚
â”œâ”€â”€ profiling/
â”‚   â”œâ”€â”€ profiler.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ s3_uploader.py
â”‚
â”œâ”€â”€ streamlit_app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ terraform/
    â”œâ”€â”€ s3.tf
    â”œâ”€â”€ glue.tf
    â”œâ”€â”€ lambda.tf
    â”œâ”€â”€ sagemaker.tf

ğŸš€ Running the Project Locally
1. Clone the repository
git clone https://github.com/your-username/cloud-bi-sales-forecasting.git
cd cloud-bi-sales-forecasting

2. Create a virtual environment
python -m venv venv
source venv/bin/activate      # Linux/Mac
venv\Scripts\activate         # Windows

3. Install dependencies
pip install -r requirements.txt

4. Start the dashboard
streamlit run streamlit_app.py


Open browser at http://localhost:8501
.

â˜ï¸ Deploying on AWS

Terraform scripts included for automated deployment of:

S3 bucket

Lambda functions

Glue crawlers & ETL jobs

SageMaker model

IAM roles

Deploy with:

terraform init
terraform apply

ğŸ“Š Sample Outputs

Sales KPIs

Product performance charts

Regional sales heatmap

Forecast vs actual plot

EOQ & inventory metrics

Dead stock list

ğŸ”® Future Enhancements

Real-time streaming ingestion (Kinesis)

Multi-user authentication (Cognito)

Deep-learning forecasting (LSTM, DeepAR)

Docker / ECS deployment

Automated model retraining (Pipelines)
